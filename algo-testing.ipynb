{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import lyricsgenius\n",
    "import numpy as np\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "import indicoio\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"0AGGE0X9UYCDMkHxZWHojX0uBIaoHNZCQbfJO8hFx0g7nj9OJYEPJl2NzdBDdgtJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAD_PLAYLIST = \"https://open.spotify.com/user/31obw73wcndofulfje4bekzfyccy/playlist/635J1gAVD4vsiqwsyhcfZX?si=FZVQod51TrmQt6CbSavs6A\"\n",
    "HAPPY_PLAYLIST = \"https://open.spotify.com/user/31obw73wcndofulfje4bekzfyccy/playlist/6OfKVgmdjZbPfjT8IAJDeY?si=AB1B4YZYQBe-HTUlbGG8Kg\"\n",
    "CLASSICAL_PLAYLIST = \"https://open.spotify.com/user/31obw73wcndofulfje4bekzfyccy/playlist/4Qy40eL0wxsmkU7SSgg1QX?si=VlOSwHi3RbKyirDSj4tUvg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping\n",
    "pull song titles from spotify, then query them on the genius api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_titles(query):\n",
    "    # Navigating to the playlist page\n",
    "    page = requests.get(query)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Based on the HTML classes on Spotify for Safari and Chrome\n",
    "    song_titles = pd.Series(soup.find_all(class_ = \"track-name\"))\n",
    "    song_titles = song_titles.apply(str)\n",
    "    html_cleaner = lambda title: re.sub(\"<.*?>\", \"\", title)\n",
    "    song_titles = song_titles.apply(html_cleaner)\n",
    "    return song_titles\n",
    "\n",
    "def scrape_artists(query):\n",
    "    page = requests.get(query)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    artists = pd.Series(soup.find_all(class_ = \"artists-albums\"))\n",
    "    artists = artists.apply(lambda title: re.sub(\"<.*?>\", \"\", str(title)))\n",
    "    return artists\n",
    "\n",
    "def clean_artists(artist_name):\n",
    "    x = artist_name.split(\"•\")[0]\n",
    "    return re.sub('\\s+', ' ', x).strip()\n",
    "\n",
    "def query_song(title, artist):\n",
    "    genius = lyricsgenius.Genius(API_KEY)\n",
    "    song = genius.search_song(title, artist) \n",
    "    if song:\n",
    "        return song.lyrics\n",
    "    elif artist == \"\":\n",
    "        return \"no lyrics found\"\n",
    "    else:\n",
    "        return query_song(title, \"\")\n",
    "\n",
    "def playlist_df(url):\n",
    "    titles = scrape_titles(url)\n",
    "    artists = scrape_artists(url).apply(clean_artists)\n",
    "    df = pd.DataFrame({\"song\": titles, \"artist\": artists})\n",
    "    df[\"lyrics\"] = df.apply(lambda x: query_song(x.song, x.artist), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sad = playlist_df(SAD_PLAYLIST)\n",
    "# happy = playlist_df(HAPPY_PLAYLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sad.to_csv(\"sad.csv\")\n",
    "# happy.to_csv(\"happy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to refresh lyrics \n",
    "sad = pd.read_csv(\"sad.csv\").iloc[:, 1:4]\n",
    "happy = pd.read_csv(\"happy.csv\").iloc[:, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Night Changes</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>[Verse 1: Zayn  &amp; Liam]\\nGoing out tonight, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This Town</td>\n",
       "      <td>Niall Horan</td>\n",
       "      <td>[Verse 1]\\nWaking up to kiss you and nobody’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Silence</td>\n",
       "      <td>Marshmello, Khalid</td>\n",
       "      <td>[Verse 1]\\nYeah, I'd rather be a lover than a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shouldn't Come Back</td>\n",
       "      <td>Demi Lovato</td>\n",
       "      <td>[Verse 1]\\nSee you calling again\\nI don't wann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stargazing</td>\n",
       "      <td>Kygo, Justin Jesso</td>\n",
       "      <td>[Verse 1: Justin Jesso]\\nYou're saying it's ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  song              artist  \\\n",
       "0        Night Changes       One Direction   \n",
       "1            This Town         Niall Horan   \n",
       "2              Silence  Marshmello, Khalid   \n",
       "3  Shouldn't Come Back         Demi Lovato   \n",
       "4           Stargazing  Kygo, Justin Jesso   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [Verse 1: Zayn  & Liam]\\nGoing out tonight, ch...  \n",
       "1  [Verse 1]\\nWaking up to kiss you and nobody’s ...  \n",
       "2  [Verse 1]\\nYeah, I'd rather be a lover than a ...  \n",
       "3  [Verse 1]\\nSee you calling again\\nI don't wann...  \n",
       "4  [Verse 1: Justin Jesso]\\nYou're saying it's ho...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Body Like A Back Road</td>\n",
       "      <td>Sam Hunt</td>\n",
       "      <td>[Verse 1]\\nGot a girl from the south side, got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>[Directed by David Dobkin]\\n\\n[Verse 1]\\nI'm h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Star</td>\n",
       "      <td>Smash Mouth</td>\n",
       "      <td>[Verse 1]\\nSomebody once told me the world is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Live While We're Young</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>[Intro]\\n\\n[Verse 1: Liam &amp; Zayn]\\nHey girl, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAN'T STOP THE FEELING! (Original Song from Dr...</td>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>no lyrics found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                song             artist  \\\n",
       "0                              Body Like A Back Road           Sam Hunt   \n",
       "1                                              Sugar           Maroon 5   \n",
       "2                                           All Star        Smash Mouth   \n",
       "3                             Live While We're Young      One Direction   \n",
       "4  CAN'T STOP THE FEELING! (Original Song from Dr...  Justin Timberlake   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [Verse 1]\\nGot a girl from the south side, got...  \n",
       "1  [Directed by David Dobkin]\\n\\n[Verse 1]\\nI'm h...  \n",
       "2  [Verse 1]\\nSomebody once told me the world is ...  \n",
       "3  [Intro]\\n\\n[Verse 1: Liam & Zayn]\\nHey girl, I...  \n",
       "4                                    no lyrics found  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "remove punctuation, and lyrical words (not recognized under stopwords)  \n",
    "detect language, convert to english if necessary  \n",
    "remove stopwords once all lyrics are in english  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english(lyric):\n",
    "    blob = TextBlob(lyric)\n",
    "    language = blob.detect_language()\n",
    "    return language == 'en'\n",
    "\n",
    "def translator(lyric):\n",
    "    blob = TextBlob(lyic)\n",
    "    if not english(lyric):\n",
    "        result = blob.translate(to='en')\n",
    "        return str(result)\n",
    "    else:\n",
    "        return lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(lyrics):\n",
    "    punc_cleaner = lambda lyric: re.sub(r\"[^\\w\\s']+\", '', lyric)\n",
    "    lyrics = punc_cleaner(lyrics)\n",
    "    lyrics = str.lower(lyrics)\n",
    "    return lyrics\n",
    "\n",
    "def remove_musical_words(lyrics):\n",
    "    r = \"(chorus|hook|intro|verse|bridge|outro|part|ft|feat)\"\n",
    "    lyrics = re.sub(r, \"\", lyrics)\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(lyric):\n",
    "    lyric = standardize(lyric)\n",
    "    lyric = remove_musical_words(lyric)\n",
    "    return lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_records(df):\n",
    "    df = df.loc[df[\"lyrics\"] != \"no lyrics found\", :]\n",
    "    english_indexes = df[\"lyrics\"].apply(english)\n",
    "    df = df.loc[english_indexes]\n",
    "    #df = df.loc[df[\"cleaned\"].apply(english), :]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before is (30, 4)\n",
      "Shape after is (24, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DJ Got Us Fallin' In Love (feat. Pitbull)</td>\n",
       "      <td>Usher, Pitbull</td>\n",
       "      <td>[Intro: Usher]\\nUsher, Usher, Usher\\nYeah, man...</td>\n",
       "      <td>usher\\nusher usher usher\\nyeah man\\n\\n 1 ushe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Starships</td>\n",
       "      <td>Nicki Minaj</td>\n",
       "      <td>[Verse 1]\\n(RedOne..., Uh)\\nLet's go to the be...</td>\n",
       "      <td>1\\nredone uh\\nlets go to the beach each\\nlets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Super Bass</td>\n",
       "      <td>Nicki Minaj</td>\n",
       "      <td>[Verse 1: Nicki Minaj]\\nThis one is for the bo...</td>\n",
       "      <td>1 nicki minaj\\nthis one is for the boys with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I Gotta Feeling</td>\n",
       "      <td>The Black Eyed Peas</td>\n",
       "      <td>[Hook]\\nI got a feeling that tonight's gonna b...</td>\n",
       "      <td>\\ni got a feeling that tonights gonna be a goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>We Are Never Ever Getting Back Together</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>[Verse 1]\\nI remember when we broke up the fir...</td>\n",
       "      <td>1\\ni remember when we broke up the first time...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         song               artist  \\\n",
       "22  DJ Got Us Fallin' In Love (feat. Pitbull)       Usher, Pitbull   \n",
       "23                                  Starships          Nicki Minaj   \n",
       "24                                 Super Bass          Nicki Minaj   \n",
       "25                            I Gotta Feeling  The Black Eyed Peas   \n",
       "26    We Are Never Ever Getting Back Together         Taylor Swift   \n",
       "\n",
       "                                               lyrics  \\\n",
       "22  [Intro: Usher]\\nUsher, Usher, Usher\\nYeah, man...   \n",
       "23  [Verse 1]\\n(RedOne..., Uh)\\nLet's go to the be...   \n",
       "24  [Verse 1: Nicki Minaj]\\nThis one is for the bo...   \n",
       "25  [Hook]\\nI got a feeling that tonight's gonna b...   \n",
       "26  [Verse 1]\\nI remember when we broke up the fir...   \n",
       "\n",
       "                                              cleaned  \n",
       "22   usher\\nusher usher usher\\nyeah man\\n\\n 1 ushe...  \n",
       "23   1\\nredone uh\\nlets go to the beach each\\nlets...  \n",
       "24   1 nicki minaj\\nthis one is for the boys with ...  \n",
       "25  \\ni got a feeling that tonights gonna be a goo...  \n",
       "26   1\\ni remember when we broke up the first time...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape before is {0}\".format(happy.shape))\n",
    "happy[\"cleaned\"] = happy[\"lyrics\"].apply(clean)\n",
    "happy = drop_records(happy)\n",
    "print(\"Shape after is {0}\".format(happy.shape))\n",
    "happy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before is (30, 4)\n",
      "Shape after is (29, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Harder To Breathe</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>[Verse 1]\\nHow dare you say that my behavior's...</td>\n",
       "      <td>1\\nhow dare you say that my behaviors unaccep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I Don’t Know Why</td>\n",
       "      <td>Imagine Dragons</td>\n",
       "      <td>[Verse 1]\\nWe could be strangers in the night\\...</td>\n",
       "      <td>1\\nwe could be strangers in the night\\nwe cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dance with Me Tonight</td>\n",
       "      <td>Olly Murs</td>\n",
       "      <td>[Intro]\\nLadies and Gentlemen, we’ve got a spe...</td>\n",
       "      <td>\\nladies and gentlemen weve got a special trea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sunday Morning</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>[Intro]\\nYeah\\n\\n[Verse 1]\\nSunday morning, ra...</td>\n",
       "      <td>\\nyeah\\n\\n 1\\nsunday morning rain is falling\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>She Will Be Loved - Radio Mix</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>IT MAY NOT BE UNNECESSARY to inform the reader...</td>\n",
       "      <td>it may not be unnecessary to inform the reader...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             song           artist  \\\n",
       "25              Harder To Breathe         Maroon 5   \n",
       "26               I Don’t Know Why  Imagine Dragons   \n",
       "27          Dance with Me Tonight        Olly Murs   \n",
       "28                 Sunday Morning         Maroon 5   \n",
       "29  She Will Be Loved - Radio Mix         Maroon 5   \n",
       "\n",
       "                                               lyrics  \\\n",
       "25  [Verse 1]\\nHow dare you say that my behavior's...   \n",
       "26  [Verse 1]\\nWe could be strangers in the night\\...   \n",
       "27  [Intro]\\nLadies and Gentlemen, we’ve got a spe...   \n",
       "28  [Intro]\\nYeah\\n\\n[Verse 1]\\nSunday morning, ra...   \n",
       "29  IT MAY NOT BE UNNECESSARY to inform the reader...   \n",
       "\n",
       "                                              cleaned  \n",
       "25   1\\nhow dare you say that my behaviors unaccep...  \n",
       "26   1\\nwe could be strangers in the night\\nwe cou...  \n",
       "27  \\nladies and gentlemen weve got a special trea...  \n",
       "28  \\nyeah\\n\\n 1\\nsunday morning rain is falling\\n...  \n",
       "29  it may not be unnecessary to inform the reader...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape before is {0}\".format(sad.shape))\n",
    "sad[\"cleaned\"] = sad[\"lyrics\"].apply(clean)\n",
    "sad = drop_records(sad)\n",
    "print(\"Shape after is {0}\".format(sad.shape))\n",
    "sad.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    happy = pd.read_csv(\"happy.csv\").iloc[:, 1:4]\n",
    "    #happy[\"cleaned\"] = happy[\"lyrics\"].apply(clean)\n",
    "    happy = drop_records(happy)\n",
    "    sad = pd.read_csv(\"sad.csv\").iloc[:, 1:4]\n",
    "    #sad[\"cleaned\"] = sad[\"lyrics\"].apply(clean)\n",
    "    sad = drop_records(sad)\n",
    "    return happy, sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy, sad = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Meaning of the Words\n",
    "extracting noun phrases  \n",
    "sentiment extracting  \n",
    "topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICO_KEY = \"345e9dbbeafeed418903dac43945c766\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    indicoio.config.api_key = INDICO_KEY\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = happy[\"lyrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "addendum = [\"yeah\", \"baby\", \"tonight\", \"baby\", \"gonna\", \"bout\", \"'bout\", \"like\",\n",
    "           \"chorus\", \"hook\", \"verse\", \"intro\", \"bridge\", \"outro\", \"pt\", \"part\",\n",
    "           \"wanna\", \"love\", \"oh\", \"ooh\"]\n",
    "stoppy = text.ENGLISH_STOP_WORDS.union(addendum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24x1744 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4195 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.6, min_df=2, \n",
    "                             stop_words=stoppy, \n",
    "                             ngram_range = (1, 4),\n",
    "                             token_pattern = \"[a-zA-Z]{3,15}\"\n",
    "                             )  \n",
    "doc_term_matrix = count_vect.fit_transform(documents.values.astype('U'))\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)  \n",
    "model = LDA.fit(doc_term_matrix)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soon\n",
      "turning\n",
      "circumstances\n",
      "closed\n",
      "plastic\n",
      "swear\n",
      "cylinder\n",
      "radio\n",
      "physical\n",
      "voice\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):  \n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.19999975, 4.20000041, 1.19999617, ..., 0.20000007, 0.20000011,\n",
       "       0.20000016])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['long', 'wayne', 'turns', 'roof', 'hand', 'cops', 'park', 'face', 'night', 'car']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['beat', 'time', 'hear', 'alright', 'song', 'body', 'young', 'crazy', 'live', 'let']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['time', 'west', 'right', 'east', 'heart', 'high', 'set', 'way', 'let', 'life']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['destiny', 'beat', 'took', 'body', 'beauty', 'eyes', 'aye', 'shut', 'dance', 'said']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['rock', 'think', 'come', 'bass', 'cause', 'good', 'got', 'let', 'night', 'boom']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):  \n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'hall', 'black', 'right', 'city', 'red', 'got', 'door', 'open', 'look', 'long', 'wayne', 'turns', 'roof', 'hand', 'cops', 'park', 'face', 'night', 'car']\n",
      "['whoa', 'mon', 'stop let', 'let live', 'party', 'stop', 'waitin', 'hell', 'weird', 'want', 'beat', 'time', 'hear', 'alright', 'song', 'body', 'young', 'crazy', 'live', 'let']\n",
      "['worth', 'stay', 'south', 'air', 'big', 'gone', 'real', 'make', 'check', 'mind', 'time', 'west', 'right', 'east', 'heart', 'high', 'set', 'way', 'let', 'life']\n",
      "['bound', 'slow just', 'slow', 'ain', 'got', 'said don', 'woman', 'dare', 'look', 'holding', 'destiny', 'beat', 'took', 'body', 'beauty', 'eyes', 'aye', 'shut', 'dance', 'said']\n",
      "['let let', 'make', 'danced', 'stop', 'yes', 'need', 'friday', 'life', 'say', 'little', 'rock', 'think', 'come', 'bass', 'cause', 'good', 'got', 'let', 'night', 'boom']\n"
     ]
    }
   ],
   "source": [
    "g = enumerate(LDA.components_)\n",
    "for i, topic in g:\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-20:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to build a topic corpus\n",
    "def give_topic_models(documents):\n",
    "    from sklearn.feature_extraction import text \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.decomposition import LatentDirichletAllocation\n",
    "    from nltk.corpus import stopwords\n",
    "    addendum = [\"yeah\", \"baby\", \"tonight\", \"baby\", \"gonna\", \"bout\", \"'bout\", \"like\",\n",
    "               \"chorus\", \"hook\", \"verse\", \"intro\", \"bridge\", \"outro\", \"pt\", \"part\",\n",
    "               \"wanna\", \"love\", \"oh\", \"ooh\"]\n",
    "    \n",
    "    stoppy = stopwords.words('english') + addendum\n",
    "    count_vect = CountVectorizer(max_df=0.6, min_df=2, stop_words=stoppy, ngram_range = (1, 4), token_pattern = \"[a-zA-Z]{3,15}\")  \n",
    "    doc_term_matrix = count_vect.fit_transform(documents.values.astype('U'))\n",
    "    LDA = LatentDirichletAllocation(n_components=5, random_state=42)  \n",
    "    model = LDA.fit(doc_term_matrix)  \n",
    "    it, result = enumerate(LDA.components_), []\n",
    "    for i, topic in it:\n",
    "        words = [count_vect.get_feature_names()[i] for i in topic.argsort()[-20:]]\n",
    "        result.append(words)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly, an issue is that the models are including arbitrary words, so it might make sense to only keep nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like there's a lot of garbage filler words to get rid of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'hall',\n",
       " 'black',\n",
       " 'right',\n",
       " 'city',\n",
       " 'red',\n",
       " 'got',\n",
       " 'door',\n",
       " 'open',\n",
       " 'look',\n",
       " 'long',\n",
       " 'wayne',\n",
       " 'turns',\n",
       " 'roof',\n",
       " 'hand',\n",
       " 'cops',\n",
       " 'park',\n",
       " 'face',\n",
       " 'night',\n",
       " 'car']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_topic_models(happy[\"lyrics\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['want',\n",
       " 'right',\n",
       " 'away',\n",
       " 'august',\n",
       " 'july',\n",
       " 'really',\n",
       " 'june',\n",
       " 'time',\n",
       " 'come',\n",
       " 'feel',\n",
       " 'april',\n",
       " 'young',\n",
       " 'make',\n",
       " 'let',\n",
       " 'bad',\n",
       " 'girl',\n",
       " 'night',\n",
       " 'won',\n",
       " 'way',\n",
       " 'just']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_topic_models(sad[\"lyrics\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(original):\n",
    "    original = standardize(original).split(\" \")\n",
    "    original = [word for word in original if word not in stoppy]\n",
    "    original = [word for word in original if len(word) > 3]\n",
    "    original = \" \".join(original)\n",
    "    blob = TextBlob(original)\n",
    "    result = blob.noun_phrases\n",
    "    result = [str(g) for g in result]\n",
    "    #result = \" \".join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [braids hair, cadillac seats chorus body road ...\n",
       "1     [david dobkin verse, i 'm, i need, knees prech...\n",
       "2     [world roll, i ai n't sharpest tool, dumb fing...\n",
       "3     [intro verse liam zayn hey girl, celebration c...\n",
       "5                                  [na na, good day na]\n",
       "6     [screenplay hamm, hard copy script, scene numb...\n",
       "9     [intro high high, high high hopes, n't dime vi...\n",
       "10    ['d flight, 'd time zone, rainbows idea, crazy...\n",
       "11    [zayn harry oh, night baby i 'll, baby i 'll y...\n",
       "12                            [lyrics song, check song]\n",
       "13    [days torture, 's california dime, 's time, n'...\n",
       "14    [impossible hierarchy helper nepal corns ma us...\n",
       "15    [straight heart, doors past guards, prechorus ...\n",
       "16    [intro chorus oh, n't dare look, shut dance, w...\n",
       "17    [adam levine travie mccoy, heart 's stereo, st...\n",
       "18    [nicki minaj yeah, young money nicki minaj jus...\n",
       "19    ['s stranger bed, head glitter room, pink flam...\n",
       "20    [verbs ai n't talkin, dine dine, lean kiss, i ...\n",
       "21    [symphonies head i, oh yeah drums, yeah trumpe...\n",
       "22    [usher usher usher usher yeah man verse usher,...\n",
       "23    [redone uh, 's beach, lets wave, drink clink, ...\n",
       "24    [nicki minaj, system top cooler system, club b...\n",
       "25    [hook i feeling, good night, good night, good ...\n",
       "26    [i 've 'cause, day i, i 'm, peace mind, indie ...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy[\"lyrics\"].apply(extract_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [zayn liam, n't kind dress, wo n't, chorus har...\n",
       "1     [kiss nobodys, funny things, stars prechorus, ...\n",
       "2     [yeah lover fighter 'cause life i 've, feeling...\n",
       "3     [oh i, ohoh prechorus, sorry sorry times, n't ...\n",
       "4     [justin jesso, 's hopeless hope, 've meteoric,...\n",
       "5     [minute stone, cold sober i, ya i, rest chorus...\n",
       "6     [goodbye plane, heart chorus, goodbye times, c...\n",
       "7     [n't strength, chorus wake, middle night, i wa...\n",
       "8     [ta 'cause, 'cause edge nervous breakdown 'cau...\n",
       "9     [oh yeah verse, wine loosen, 's fly, nasty loo...\n",
       "10    [i 'll, fast prechorus, sleep 'cause, wake i s...\n",
       "11    [insides feeling hollow, hard pill swallow yea...\n",
       "12    [intro oh yeah oh yeah verse, wo n't bend, i '...\n",
       "13    [oh oh words mend things, night sleep, night i...\n",
       "14    [black town i, 's stupid, chorus i 'm corner, ...\n",
       "15    [516pm mst octoberoctober 6jesse powell jesse ...\n",
       "16    [oh eyes eyes, 're shinin', hair hair, day yea...\n",
       "17    [eyes relax, heavy thoughts, time verse, gravi...\n",
       "18    [wake bloodshot eye struggle memorize, thighs ...\n",
       "19    [n't strength, chorus wake, middle night, i wa...\n",
       "21    [sayin' i, emotion baby i, kind betray, babe p...\n",
       "22    [i dont, beautiful smile eyes, type amnesia th...\n",
       "23    [morphine door 'cause medication, 's religion,...\n",
       "24    [adam levine travie mccoy, heart 's stereo, st...\n",
       "25    [dare behavior 's, critical i tendency, step '...\n",
       "26    [strangers night, faces crowd, headlights prec...\n",
       "27    [intro ladies gentlemen weve, im friend, lets ...\n",
       "28    [intro yeah verse, sunday morning rain, share ...\n",
       "29    [reflections origin correspondence author, you...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad[\"lyrics\"].apply(extract_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :  1319\n",
      "life :  376\n",
      "bruce :  317\n",
      "it's :  201\n",
      "vicki :  186\n",
      "moment :  177\n",
      "just :  174\n",
      "int :  166\n",
      "night :  165\n",
      "selina :  148\n",
      "alfred :  146\n",
      "penguin :  139\n",
      "know :  137\n",
      "batman :  137\n",
      "way :  130\n",
      "got :  119\n",
      "don't :  118\n",
      "i'm :  111\n",
      "let :  105\n",
      "tiptree :  102\n",
      "time :  95\n",
      "right :  95\n",
      "car :  95\n",
      "set :  89\n",
      "good :  84\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = happy[\"lyrics\"].apply(standardize).apply(extract_nouns)\n",
    "\n",
    "a = \"\".join(happy[\"lyrics\"].tolist())\n",
    "\n",
    "wordcount = {}\n",
    "# split this\n",
    "for word in a.split():\n",
    "    word = standardize(word)\n",
    "    if word not in stoppy:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "word_counter = collections.Counter(wordcount)\n",
    "for word, count in word_counter.most_common(25):\n",
    "    print(word, \": \", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
